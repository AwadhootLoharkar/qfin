{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QSdydwaffrjn"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nV2Jp5lyKE_B",
    "outputId": "9db9cc85-b129-456e-98b3-9a49da8092e6"
   },
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "from requests.exceptions import HTTPError\n",
    "import pandas as pd\n",
    "\n",
    "# List of ticker symbols\n",
    "ticker_symbols = [\n",
    "    \"RELIANCE.NS\",\n",
    "    \"TCS.NS\",\n",
    "    \"HDB\",\n",
    "    \"IBN\",\n",
    "    \"INFY\",\n",
    "    \"SBIN.NS\",\n",
    "    \"LICI.NS\",\n",
    "    \"BHARTIARTL.NS\",\n",
    "    \"HINDUNILVR.NS\",\n",
    "    \"ITC.NS\",\n",
    "    \"LT.NS\"\n",
    "]\n",
    "\n",
    "\n",
    "# Counters\n",
    "total_companies = len(ticker_symbols)\n",
    "discarded_companies = 0\n",
    "available_companies = 0\n",
    "\n",
    "# Set start and end dates\n",
    "start_date = '2014-01-01'\n",
    "end_date = '2024-01-01'\n",
    "\n",
    "# Create an empty DataFrame to store data for companies with sector and industry\n",
    "all_stock_data = pd.DataFrame()\n",
    "\n",
    "# Loop through each ticker symbol\n",
    "for ticker_symbol in ticker_symbols:\n",
    "    try:\n",
    "        # Create a Ticker object\n",
    "        ticker = yf.Ticker(ticker_symbol)\n",
    "\n",
    "        # Get the info dictionary containing various information including sector and industry\n",
    "        info = ticker.info\n",
    "\n",
    "        # Get sector and industry information\n",
    "        sector = info.get('sector')\n",
    "        industry = info.get('industry')\n",
    "\n",
    "        # Check if both sector and industry are not None\n",
    "        if sector is not None and industry is not None:\n",
    "            # Download historical data for the current ticker symbol\n",
    "            stock_data = yf.download(ticker_symbol, start=start_date, end=end_date)\n",
    "\n",
    "            # Add stock information as columns to the DataFrame\n",
    "            stock_data['Company Name'] = info['longName']\n",
    "            stock_data['Sector'] = sector\n",
    "            stock_data['Industry'] = industry\n",
    "\n",
    "            # Append the stock data to the DataFrame for all stocks\n",
    "            all_stock_data = pd.concat([all_stock_data, stock_data])\n",
    "\n",
    "            available_companies += 1\n",
    "        else:\n",
    "            discarded_companies += 1\n",
    "    except HTTPError as e:\n",
    "        if e.response.status_code == 404:\n",
    "            print(f\"Error 404: Ticker {ticker_symbol} not found. Discarding...\")\n",
    "            discarded_companies += 1\n",
    "\n",
    "# Print summary\n",
    "print(\"Summary:\")\n",
    "print(\"Total companies input:\", total_companies)\n",
    "print(\"Number of companies discarded:\", discarded_companies)\n",
    "print(\"Number of companies available with sector and industry:\", available_companies)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"\\nStock Data:\")\n",
    "print(all_stock_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "gTKHQFdxK3yd",
    "outputId": "48aa43ec-f0bc-40e2-e08e-4812b140ee74"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_stock_data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EvTNQc_TL8t4"
   },
   "outputs": [],
   "source": [
    "df.rename(columns={'Company Name': 'company'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EBrg71dNMSpy",
    "outputId": "47be6095-8890-46fb-e3b8-fd08f9702395"
   },
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_rows', None)\n",
    "company_counts=df['company_counts'] = df['company'].value_counts()\n",
    "company_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LhJXq5s9MBRS",
    "outputId": "6aa47139-b229-4315-f93c-52eec7ab6245"
   },
   "outputs": [],
   "source": [
    "num_companies_with_2465 = (company_counts == 2465).sum()\n",
    "num_companies_with_2465\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "dH9muoXGWEGC",
    "outputId": "befc2ddd-3476-4974-9222-d10d6b34f0aa"
   },
   "outputs": [],
   "source": [
    "df['days_count'] = df['company'].map(df['company'].value_counts())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "juLpFo0PYF8E"
   },
   "outputs": [],
   "source": [
    "selected_companies = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fR6EPmBWRRj-"
   },
   "outputs": [],
   "source": [
    "for company, days_count in df.groupby('company')['days_count'].first().items():\n",
    "    if days_count == 2465:\n",
    "        selected_companies.append(company)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "UyJGNAiSRQm5",
    "outputId": "c0c5b99a-73e5-49c2-be0f-05fc656618ac"
   },
   "outputs": [],
   "source": [
    "df1 = df[df['company'].isin(selected_companies)]\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ZB89qjPBXMy",
    "outputId": "353c4978-78ff-4658-bc3a-dc0475c7b952"
   },
   "outputs": [],
   "source": [
    "df1.drop(columns=['company_counts'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TgxprOUrf6cl"
   },
   "outputs": [],
   "source": [
    "import ta\n",
    "\n",
    "import pandas as pd\n",
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "from pypfopt import risk_models\n",
    "from pypfopt import expected_returns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fLIEt8iLtf1d"
   },
   "outputs": [],
   "source": [
    "List_of_companies = list(set(df1['company'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "mdlGE2rut2s0",
    "outputId": "5fb393d2-3684-4d4b-a679-9a3400b6043c"
   },
   "outputs": [],
   "source": [
    "All_df_list = []\n",
    "for comp in List_of_companies:\n",
    "#     print(comp)\n",
    "    Individual_comp = df1.loc[df1['company'] == comp]\n",
    "    Individual_comp = Individual_comp.sort_values('Date')\n",
    "    Individual_comp['prev close'] = Individual_comp['Adj Close'].shift(1)\n",
    "    Individual_comp['Returns'] = (Individual_comp['Adj Close'] - Individual_comp['prev close'])/Individual_comp['prev close']\n",
    "    All_df_list.append(Individual_comp)\n",
    "final_df = pd.concat(All_df_list)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CAesH0aGuIkq"
   },
   "outputs": [],
   "source": [
    "df2=final_df.pivot(columns=\"company\",values=\"Returns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 752
    },
    "id": "YN0BdxyjRRRW",
    "outputId": "8596d545-e734-4a01-b89d-70316beb20f1"
   },
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cI4BkMFMDdWl",
    "outputId": "26dd00c4-c9b8-424a-bcc9-15d27310e6bc"
   },
   "outputs": [],
   "source": [
    "# Get unique sectors\n",
    "sectors = df1[\"Sector\"].unique()\n",
    "\n",
    "# Create an empty dictionary to store sector-wise company names\n",
    "sector_companies = {}\n",
    "\n",
    "# Iterate over each sector\n",
    "for sector in sectors:\n",
    "    # Filter data for the current sector\n",
    "    sector_data = df1[df1[\"Sector\"] == sector]\n",
    "\n",
    "    # Get unique company names within the sector\n",
    "    companies = sector_data[\"company\"].unique().tolist()\n",
    "\n",
    "    # Store the list of company names in the dictionary\n",
    "    sector_companies[sector] = companies\n",
    "\n",
    "sector_companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 752
    },
    "id": "se-Gt46kG7Ag",
    "outputId": "b0f39b7f-55b0-4a68-89ed-5276aa80618b"
   },
   "outputs": [],
   "source": [
    "data2=final_df.pivot(columns=\"company\",values=\"Adj Close\")\n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 646
    },
    "id": "LN-gEd6MHLLc",
    "outputId": "1923bff3-8b18-4aaa-9520-8e0eb04eeaa3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df contains your data with columns 'sector', 'company', and 'adj close'\n",
    "\n",
    "# Pivot the data to get adjusted close values for each company within each sector\n",
    "sector_adj_close = df1.pivot_table(index='Date',columns= 'Sector', values='Adj Close')\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "sector_adj_close\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZP4X5UKNBBDo",
    "outputId": "b8a8083e-a6f1-48f1-9846-9c3fca98b4dc"
   },
   "outputs": [],
   "source": [
    "# mean variance \n",
    "import pandas as pd\n",
    "from pypfopt import expected_returns, risk_models\n",
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "\n",
    "# Assuming selected_data contains your data with columns 'company', 'Sector', and 'Adj Close'\n",
    "\n",
    "# Get unique sectors and create a dictionary to store sector-wise company names\n",
    "sectors = df1[\"Sector\"].unique()\n",
    "sector_companies = {}\n",
    "for sector in sectors:\n",
    "    sector_data = df1[df1[\"Sector\"] == sector]\n",
    "    companies = sector_data[\"company\"].unique().tolist()\n",
    "    sector_companies[sector] = companies\n",
    "\n",
    "# Define sector mappings based on the sector-wise company names dictionary\n",
    "sector_mapper = {company: sector for sector, companies in sector_companies.items() for company in companies}\n",
    "\n",
    "# Define sector constraints based on the sector-wise company names dictionary\n",
    "sector_lower = {sector: 0 for sector in sectors}\n",
    "sector_upper = {sector: 0.1 for sector in sectors}\n",
    "\n",
    "# Calculate expected returns and the covariance matrix of the portfolio\n",
    "mu = expected_returns.mean_historical_return(data2)\n",
    "S = risk_models.sample_cov(data2)\n",
    "\n",
    "# Create the Efficient Frontier Object\n",
    "ef = EfficientFrontier(mu, S, solver='ECOS')\n",
    "\n",
    "# Add sector constraints to the Efficient Frontier\n",
    "ef.add_sector_constraints(sector_mapper, sector_lower, sector_upper)\n",
    "\n",
    "# Optimize for the maximum Sharpe ratio\n",
    "weights = ef.max_sharpe()\n",
    "\n",
    "# Clean the raw weights and print them\n",
    "cleaned_weights = ef.clean_weights()\n",
    "print(cleaned_weights)\n",
    "\n",
    "# Calculate and print the portfolio performance\n",
    "ef.portfolio_performance(verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Filter out zero-weighted assets\n",
    "non_zero_weights = {asset: weight for asset, weight in cleaned_weights.items() if weight != 0}\n",
    "\n",
    "# Extract labels and values from non-zero weights\n",
    "labels = list(non_zero_weights.keys())\n",
    "values = list(non_zero_weights.values())\n",
    "\n",
    "# Create a pie chart using Plotly\n",
    "fig = px.pie(names=labels, values=values, title='Non-zero Weight Portfolio Composition')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rDLOrvlGhMJE",
    "outputId": "28d3dcdb-13d5-4b03-e0af-c8b6682882ed"
   },
   "outputs": [],
   "source": [
    "# EFFICIENT CVAR\n",
    "from pypfopt import EfficientCVaR\n",
    "\n",
    "# Calculate expected returns and the covariance matrix of the portfolio\n",
    "mu = expected_returns.mean_historical_return(data2)\n",
    "S = risk_models.sample_cov(data2)\n",
    "\n",
    "# Create the Efficient Frontier Object with CVaR\n",
    "ef = EfficientCVaR(mu, S)\n",
    "\n",
    "# Add sector constraints to the Efficient Frontier\n",
    "ef.add_sector_constraints(sector_mapper, sector_lower, sector_upper)\n",
    "\n",
    "# Optimize for the minimum CVaR\n",
    "weights = ef.min_cvar()\n",
    "\n",
    "# Clean the raw weights and print them\n",
    "cleaned_weightss = ef.clean_weights()\n",
    "print(cleaned_weightss)\n",
    "\n",
    "\n",
    "\n",
    "# Calculate and print the portfolio performance\n",
    "ef.portfolio_performance(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Filter out zero-weighted assets\n",
    "non_zero_weightss = {asset: weight for asset, weight in cleaned_weightss.items() if weight != 0}\n",
    "\n",
    "# Extract labels and values from non-zero weights\n",
    "labels = list(non_zero_weightss.keys())\n",
    "values = list(non_zero_weightss.values())\n",
    "\n",
    "# Create a pie chart using Plotly\n",
    "fig = px.pie(names=labels, values=values, title='Non-zero Weight Portfolio Composition')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SECTOR WISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean variance \n",
    "import pandas as pd\n",
    "from pypfopt import expected_returns, risk_models\n",
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "\n",
    "# Assuming selected_data contains your data with columns 'company', 'Sector', and 'Adj Close'\n",
    "\n",
    "# Get unique sectors and create a dictionary to store sector-wise company names\n",
    "sectors = df1[\"Sector\"].unique()\n",
    "sector_companies = {}\n",
    "for sector in sectors:\n",
    "    sector_data = df1[df1[\"Sector\"] == sector]\n",
    "    companies = sector_data[\"company\"].unique().tolist()\n",
    "    sector_companies[sector] = companies\n",
    "\n",
    "# Define sector mappings based on the sector-wise company names dictionary\n",
    "sector_mapper = {company: sector for sector, companies in sector_companies.items() for company in companies}\n",
    "\n",
    "# Define sector constraints based on the sector-wise company names dictionary\n",
    "sector_lower = {sector: 0 for sector in sectors}\n",
    "sector_upper = {sector: 0.1 for sector in sectors}\n",
    "\n",
    "# Calculate expected returns and the covariance matrix of the portfolio\n",
    "mu = expected_returns.mean_historical_return(sector_adj_close)\n",
    "S = risk_models.sample_cov(sector_adj_close)\n",
    "\n",
    "# Create the Efficient Frontier Object\n",
    "ef = EfficientFrontier(mu, S, solver='ECOS')\n",
    "\n",
    "# Add sector constraints to the Efficient Frontier\n",
    "ef.add_sector_constraints(sector_mapper, sector_lower, sector_upper)\n",
    "\n",
    "# Optimize for the maximum Sharpe ratio\n",
    "weights = ef.max_sharpe()\n",
    "\n",
    "# Clean the raw weights and print them\n",
    "cleaned_weights = ef.clean_weights()\n",
    "print(cleaned_weights)\n",
    "\n",
    "# Calculate and print the portfolio performance\n",
    "ef.portfolio_performance(verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Filter out zero-weighted assets\n",
    "non_zero_weights = {asset: weight for asset, weight in cleaned_weights.items() if weight != 0}\n",
    "\n",
    "# Extract labels and values from non-zero weights\n",
    "labels = list(non_zero_weights.keys())\n",
    "values = list(non_zero_weights.values())\n",
    "\n",
    "# Create a pie chart using Plotly\n",
    "fig = px.pie(names=labels, values=values, title='Non-zero Weight Portfolio Composition')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EFFICIENT CVAR\n",
    "from pypfopt import EfficientCVaR\n",
    "\n",
    "# Calculate expected returns and the covariance matrix of the portfolio\n",
    "mu = expected_returns.mean_historical_return(sector_adj_close)\n",
    "S = risk_models.sample_cov(sector_adj_close)\n",
    "\n",
    "# Create the Efficient Frontier Object with CVaR\n",
    "ef = EfficientCVaR(mu, S, beta= 0.70)\n",
    "\n",
    "# Add sector constraints to the Efficient Frontier\n",
    "ef.add_sector_constraints(sector_mapper, sector_lower, sector_upper)\n",
    "\n",
    "# Optimize for the minimum CVaR\n",
    "weights = ef.min_cvar()\n",
    "\n",
    "# Clean the raw weights and print them\n",
    "cleaned_weightss = ef.clean_weights()\n",
    "print(cleaned_weightss)\n",
    "\n",
    "\n",
    "\n",
    "# Calculate and print the portfolio performance\n",
    "ef.portfolio_performance(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Filter out zero-weighted assets\n",
    "non_zero_weightss = {asset: weight for asset, weight in cleaned_weightss.items() if weight != 0}\n",
    "\n",
    "# Extract labels and values from non-zero weights\n",
    "labels = list(non_zero_weightss.keys())\n",
    "values = list(non_zero_weightss.values())\n",
    "\n",
    "# Create a pie chart using Plotly\n",
    "fig = px.pie(names=labels, values=values, title='Non-zero Weight Portfolio Composition')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 651
    },
    "id": "3hNi8R5Nt3GZ",
    "outputId": "ff238033-454a-474e-a507-2c5bd47a7e7f"
   },
   "outputs": [],
   "source": [
    "'''import pandas as pd\n",
    "import numpy as np\n",
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "from pypfopt import risk_models\n",
    "from pypfopt import expected_returns\n",
    "\n",
    "# Assuming `df1` is your DataFrame containing stock data\n",
    "List_of_companies = list(set(df1['company'].unique()))\n",
    "\n",
    "All_df_list = []\n",
    "for comp in List_of_companies:\n",
    "    Individual_comp = df1.loc[df1['company'] == comp]\n",
    "    Individual_comp = Individual_comp.sort_values('Date')\n",
    "    Individual_comp['prev close'] = Individual_comp['Adj Close'].shift(1)\n",
    "    Individual_comp['Returns'] = (Individual_comp['Adj Close'] - Individual_comp['prev close']) / Individual_comp[\n",
    "        'prev close']\n",
    "    All_df_list.append(Individual_comp)\n",
    "final_df = pd.concat(All_df_list)\n",
    "\n",
    "# Pivot the DataFrame to get returns for each company\n",
    "returns_df = final_df.pivot(columns=\"company\", values=\"Returns\")\n",
    "\n",
    "# Remove rows with NaN or infinite values\n",
    "clean_returns_df = returns_df.dropna().replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "# Calculate expected returns and sample covariance matrix of asset returns\n",
    "mu = expected_returns.mean_historical_return(clean_returns_df)\n",
    "S = risk_models.sample_cov(clean_returns_df)\n",
    "\n",
    "# Initialize EfficientFrontier\n",
    "ef = EfficientFrontier(mu, S)\n",
    "\n",
    "# Optimize for maximum Sharpe ratio\n",
    "weights = ef.max_sharpe()\n",
    "\n",
    "# Clean the weights\n",
    "cleaned_weights = ef.clean_weights()\n",
    "\n",
    "# Display the cleaned weights\n",
    "print(cleaned_weights)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NoC58i-s3AQB",
    "outputId": "db437744-6181-4ff3-a647-b488891a635e"
   },
   "outputs": [],
   "source": [
    "'''import pandas as pd\n",
    "import numpy as np\n",
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "from pypfopt import risk_models\n",
    "from pypfopt import expected_returns\n",
    "\n",
    "# Step 1: Calculate expected returns and covariance matrix\n",
    "returns = df2\n",
    "mean_returns = returns.mean()\n",
    "cov_matrix = returns.cov()\n",
    "\n",
    "# Step 2: Instantiate EfficientFrontier object with a lower risk-free rate value and specify the solver\n",
    "ef = EfficientFrontier(mean_returns, cov_matrix, solver='ECOS')\n",
    "\n",
    "# Step 3: Define objective and constraints (optional)\n",
    "# Here we'll use default constraints (weights between 0 and 1, sum of weights = 1)\n",
    "\n",
    "# Step 4: Optimize for maximum Sharpe ratio with a lower risk-free rate value\n",
    "#risk_free_rate = 0.0001  # Adjust the risk-free rate value as needed\n",
    "weights_max_sharpe = ef.max_sharpe(risk_free_rate)\n",
    "weigg]\n",
    "# Print optimized weights for minimum volatility and maximum Sharpe ratio\n",
    "print(\"Weights for minimum volatility portfolio:\")\n",
    "print(weights_min_volatility)\n",
    "print(\"\\nWeights for maximum Sharpe ratio portfolio:\")\n",
    "print(weights_max_sharpe)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 582
    },
    "id": "cC5_9Rr29wNj",
    "outputId": "fb778007-9108-4cc0-fad8-6e6d5f6e2928"
   },
   "outputs": [],
   "source": [
    "'''import pandas as pd\n",
    "import numpy as np\n",
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "from pypfopt import risk_models\n",
    "from pypfopt import expected_returns\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Step 1: Calculate expected returns and covariance matrix\n",
    "returns = df2\n",
    "mean_returns = returns.mean()\n",
    "cov_matrix = returns.cov()\n",
    "\n",
    "# Step 2: Instantiate EfficientFrontier object with a lower risk-free rate value and specify the solver\n",
    "ef = EfficientFrontier(mean_returns, cov_matrix, solver='ECOS')\n",
    "\n",
    "# Step 3: Define objective and constraints (optional)\n",
    "# Here we'll use default constraints (weights between 0 and 1, sum of weights = 1)\n",
    "\n",
    "# Step 4: Optimize for maximum Sharpe ratio with a lower risk-free rate value\n",
    "#risk_free_rate = 0.0001  # Adjust the risk-free rate value as needed\n",
    "weights_max_sharpe = ef.max_sharpe(risk_free_rate)\n",
    "\n",
    "# Create a Pie Chart using Plotly\n",
    "fig = go.Figure(data=[go.Pie(labels=weights_max_sharpe.keys(), values=weights_max_sharpe.values())])\n",
    "\n",
    "# Set layout options\n",
    "fig.update_layout(title='Optimized Weights for Maximum Sharpe Ratio Portfolio')\n",
    "\n",
    "# Show the plot\n",
    "fig.show()'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cLBTjY6q9wKS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sTEYYMLa9wHz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wlYIMa_V9wFb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ooUw95Il9wDL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qkojj2DA9wA_"
   },
   "outputs": [],
   "source": [
    "# Monte Carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C3IOjKPItlrC",
    "outputId": "07ef33af-a2e5-40a2-fc26-d253b588faee"
   },
   "outputs": [],
   "source": [
    "'''import numpy as np\n",
    "np.random.seed(1)\n",
    "# Weight each security\n",
    "weights = np.random.random((389,1))\n",
    "# normalize it, so that some is one\n",
    "weights /= np.sum(weights)\n",
    "print(f'Normalized Weights : {weights.flatten()}')\n",
    "\n",
    "# We generally do log return instead of return\n",
    "log_ret = np.log(data2/ data2.shift(1))\n",
    "log_ret\n",
    "\n",
    "# Expected return (weighted sum of mean returns). Mult by 252 as we always do annual calculation and year has 252 business days\n",
    "exp_ret = log_ret.mean().dot(weights)*252\n",
    "print(f'\\nExpected return of the portfolio is : {exp_ret[0]}')\n",
    "# Exp Volatility (Risk)\n",
    "exp_vol = np.sqrt(weights.T.dot(252*log_ret.cov().dot(weights)))\n",
    "print(f'\\nVolatility of the portfolio: {exp_vol[0][0]}')\n",
    "\n",
    "# Sharpe ratio\n",
    "sr = exp_ret / exp_vol\n",
    "print(f'\\nSharpe ratio of the portfolio: {sr[0][0]}')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RxQCt4m4tljX"
   },
   "outputs": [],
   "source": [
    "''''# number of simulation\n",
    "#n = 50_000\n",
    "n = 10\n",
    "\n",
    "port_weights = np.zeros(shape=(n,len(data2.columns)))\n",
    "port_volatility = np.zeros(n)\n",
    "port_sr = np.zeros(n)\n",
    "port_return = np.zeros(n)\n",
    "\n",
    "num_securities = len(data2.columns)\n",
    "# num_securities\n",
    "for i in range(n):\n",
    "    # Weight each security\n",
    "    weights = np.random.random(389)\n",
    "    # normalize it, so that some is one\n",
    "    weights /= np.sum(weights)\n",
    "    port_weights[i,:] = weights\n",
    "    #     print(f'Normalized Weights : {weights.flatten()}')\n",
    "\n",
    "    # Expected return (weighted sum of mean returns). Mult by 252 as we always do annual calculation and year has 252 business days\n",
    "    exp_ret = log_ret.mean().dot(weights)*252\n",
    "    port_return[i] = exp_ret\n",
    "#     print(f'\\nExpected return is : {exp_ret[0]}')\n",
    "\n",
    "    # Exp Volatility (Risk)\n",
    "    exp_vol = np.sqrt(weights.T.dot(252*log_ret.cov().dot(weights)))\n",
    "    port_volatility[i] = exp_vol\n",
    "#     print(f'\\nVolatility : {exp_vol[0][0]}')\n",
    "\n",
    "    # Sharpe ratio\n",
    "    sr = exp_ret / exp_vol\n",
    "    port_sr[i] = sr\n",
    "#   print(f'\\nSharpe ratio : {sr[0][0]}')''''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zrU9Z0GCtlhK"
   },
   "outputs": [],
   "source": [
    "'''# Index of max Sharpe Ratio\n",
    "max_sr = port_sr.max()\n",
    "ind = port_sr.argmax()\n",
    "# Return and Volatility at Max SR\n",
    "max_sr_ret = port_return[ind]\n",
    "max_sr_vol = port_volatility[ind]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "b0OTqEjGtle6",
    "outputId": "a32eabb6-a149-40da-8102-275871a0c35c"
   },
   "outputs": [],
   "source": [
    "'''plt.figure(figsize=(20,15))\n",
    "plt.scatter(port_volatility,port_return,c=port_sr, cmap='plasma')\n",
    "plt.colorbar(label='Sharpe Ratio')\n",
    "plt.xlabel('Volatility', fontsize=15)\n",
    "plt.ylabel('Return', fontsize=15)\n",
    "plt.title('Efficient Frontier (Bullet Plot)', fontsize=15)\n",
    "plt.scatter(max_sr_vol, max_sr_ret, c='blue', s=150, edgecolors='red', marker='o', label='Max \\\n",
    "Sharpe ratio Portfolio')\n",
    "plt.legend();'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1WCJtdzFtlcl",
    "outputId": "71314eb2-3952-4f9b-ea7b-5f50d7c6f90c"
   },
   "outputs": [],
   "source": [
    "'''for weight, company in zip(port_weights[ind],company):\n",
    "    print(f'{round(weight * 100, 2)} % of {company} should be bought.')\n",
    "\n",
    "# best portfolio return\n",
    "print(f'\\nMarkowitz optimal portfolio return is : {round(max_sr_ret * 100, 2)}% with volatility \\\n",
    "{max_sr_vol}')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Htf5zKM-tlaP"
   },
   "outputs": [],
   "source": [
    "'''from scipy import optimize'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tPy-C_d_xIaw"
   },
   "outputs": [],
   "source": [
    "'''log_mean = log_ret.mean() * 252\n",
    "cov = log_ret.cov() * 252'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "903_nElPxIXO"
   },
   "outputs": [],
   "source": [
    "''''# Some helper functions\n",
    "def get_ret_vol_sr(weights):\n",
    "    weights = np.array(weights)\n",
    "    ret = log_mean.dot(weights)\n",
    "    vol = np.sqrt(weights.T.dot(cov.dot(weights)))\n",
    "    sr = ret / vol\n",
    "    return np.array([ret, vol, sr])\n",
    "\n",
    "# Negate Sharpe ratio as we need to max it but Scipy minimize the given function\n",
    "def neg_sr(weights):\n",
    "    return get_ret_vol_sr(weights)[-1] * -1\n",
    "\n",
    "# check sum of weights\n",
    "def check_sum(weights):\n",
    "    return np.sum(weights) - 1\n",
    "\n",
    "# Constraints for the optimization problem\n",
    "cons = {'type':'eq','fun':check_sum}\n",
    "# bounds on weights\n",
    "bounds = [(0,1)] * 389\n",
    "\n",
    "# initial guess for optimization to start with\n",
    "init_guess = [.25 for _ in range(389)]\n",
    "\n",
    "\n",
    "# Call minimizer\n",
    "opt_results = optimize.minimize(neg_sr, init_guess, constraints=cons, bounds=bounds, method='SLSQP')''''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r4uBQFwVxIUb",
    "outputId": "d2207dee-0289-4dd7-9c5e-55a6b9cb7740"
   },
   "outputs": [],
   "source": [
    "'''optimal_weights = opt_results.x\n",
    "# optimal_weights\n",
    "for st, i in zip(company,optimal_weights):\n",
    "    print(f'Stock {st} has weight {np.round(i*100,2)} %')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sRdtoa4PxISK",
    "outputId": "1601819a-4656-4bf2-bef6-8acecef8be6c"
   },
   "outputs": [],
   "source": [
    "'''mc_weights = port_weights[ind]\n",
    "for st, i in zip(company,mc_weights):\n",
    "    print(f'Stock {st} has weight {np.round(i*100,2)} %')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U9plk9EqxIP2",
    "outputId": "68ec0d1f-aaa0-4bb1-e911-f4f972d87056"
   },
   "outputs": [],
   "source": [
    "'''# Comparing two results we see that we get very close results\n",
    "(optimal_weights - mc_weights)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b2racwQexINe",
    "outputId": "b45bfb49-f8ff-451e-af42-08383fccdb8b"
   },
   "outputs": [],
   "source": [
    "'''get_ret_vol_sr(optimal_weights), get_ret_vol_sr(mc_weights)\n",
    "\n",
    "print('For a given portfolio we have: (Using SciPy optimizer)\\n \\n')\n",
    "for i, j in enumerate('Return Volatility SharpeRatio'.split()):\n",
    "    print(f'{j} is : {get_ret_vol_sr(optimal_weights)[i]}\\n')\n",
    "\n",
    "print('For a given portfolio we have: (Using Monte Carlo)\\n \\n')\n",
    "for i, j in enumerate('Return Volatility SharpeRatio'.split()):\n",
    "    print(f'{j} is : {get_ret_vol_sr(mc_weights)[i]}\\n')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ffdsx1amxIK-"
   },
   "outputs": [],
   "source": [
    "'''frontier_y = np.linspace(port_return.min(), port_return.max(), 10)\n",
    "frontier_vol = []\n",
    "\n",
    "def minimize_vol(weights):\n",
    "    return get_ret_vol_sr(weights)[1]\n",
    "\n",
    "for possible_ret in frontier_y:\n",
    "    cons = ({'type':'eq','fun':check_sum},\n",
    "            {'type':'eq','fun':lambda w:get_ret_vol_sr(w)[0] - possible_ret})\n",
    "    result = optimize.minimize(minimize_vol, init_guess, method='SLSQP', constraints=cons, bounds=bounds)\n",
    "    frontier_vol.append(result['fun']) '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "zEZ1Qy5TxIIZ",
    "outputId": "74031fbf-0f0a-4b57-c02d-506067a26eb0"
   },
   "outputs": [],
   "source": [
    "'''plt.figure(figsize=(20,15))\n",
    "plt.scatter(port_volatility,port_return,c=port_sr, cmap='plasma')\n",
    "plt.colorbar(label='Sharpe Ratio')\n",
    "plt.xlabel('Volatility', fontsize=15)\n",
    "plt.ylabel('Return', fontsize=15)\n",
    "plt.title('Efficient Frontier', fontsize=15)\n",
    "plt.scatter(max_sr_vol, max_sr_ret, c='blue', s=150, edgecolors='red', marker='o')\n",
    "\n",
    "plt.plot(frontier_vol, frontier_y, c='magenta', ls='--', lw=3, label='Efficient Frontier')\n",
    "plt.legend();'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "Ss9Fb6q9CyUr",
    "outputId": "f1aff322-c69f-49db-9bbf-f0e301056cdb"
   },
   "outputs": [],
   "source": [
    "''''import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Sample stock returns data\n",
    "returns = df2\n",
    "\n",
    "# Calculate the covariance matrix\n",
    "cov_matrix = np.cov(returns)\n",
    "\n",
    "def risk_contribution(weights, cov_matrix):\n",
    "    port_variance = np.dot(weights.T, np.dot(cov_matrix, weights))\n",
    "    risk_contributions = weights * np.dot(cov_matrix, weights) / port_variance\n",
    "    return risk_contributions\n",
    "\n",
    "def target_risk(weights, cov_matrix, target_risk):\n",
    "    return np.sum(np.square(risk_contribution(weights, cov_matrix)) - target_risk)\n",
    "\n",
    "def calculate_weights(cov_matrix, target_risk):\n",
    "    num_assets = cov_matrix.shape[0]\n",
    "    init_weights = np.ones(num_assets) / num_assets\n",
    "    bounds = ((0, 1),) * num_assets  # Bounds for weights (0 to 1)\n",
    "    constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})  # Sum of weights equal to 1\n",
    "    optimized = minimize(target_risk, init_weights, args=(cov_matrix, target_risk),\n",
    "                         bounds=bounds, constraints=constraints)\n",
    "    return optimized.x\n",
    "\n",
    "# Target risk (adjust according to your preferences)\n",
    "target_risk = 0.03\n",
    "\n",
    "# Calculate weights using risk parity method\n",
    "weights = calculate_weights(cov_matrix, target_risk)\n",
    "\n",
    "print(\"Risk Parity Weights:\", weights)\n",
    "print(\"Risk Contributions:\", risk_contribution(weights, cov_matrix))\n",
    "''''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xOMXsJ6UpvSG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cCPpKdqLHLAa"
   },
   "outputs": [],
   "source": [
    "'''import QuantLib as ql\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Sample data\n",
    "returns = df2\n",
    "# Calculate covariance matrix\n",
    "cov_matrix = np.cov(returns)\n",
    "\n",
    "# Define the objective function\n",
    "def objective(weights, cov_matrix):\n",
    "    port_variance = np.dot(weights.T, np.dot(cov_matrix, weights))\n",
    "    return port_variance\n",
    "\n",
    "# Define the constraint (sum of weights equals 1)\n",
    "constraints = ({'type': 'eq', 'fun': lambda weights: np.sum(weights) - 1})\n",
    "\n",
    "# Define initial guess for weights\n",
    "init_weights = np.ones(len(returns)) / len(returns)\n",
    "\n",
    "# Optimize using SciPy\n",
    "result = minimize(objective, init_weights, args=(cov_matrix,), constraints=constraints)\n",
    "\n",
    "# Extract optimized weights\n",
    "optimal_weights = result.x\n",
    "\n",
    "print(\"Optimized Weights:\", optimal_weights)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hEGtwQdqpsXA"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 7))\n",
    "for c in data2.columns.values:\n",
    "    plt.plot(data2.index, data2[c], lw=3, alpha=0.8,label=c)\n",
    "plt.legend(loc='upper left', fontsize=9)\n",
    "plt.ylabel('price in Rs')\n",
    "\n",
    "def portfolio_annualised_performance(weights, mean_returns, cov_matrix):\n",
    "    returns = np.sum(mean_returns*weights ) *252\n",
    "    std = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights))) * np.sqrt(252)\n",
    "    return std, returns\n",
    "\n",
    "def random_portfolios(num_portfolios, mean_returns, cov_matrix,risk_free_rate):\n",
    "    results = np.zeros((3, num_portfolios))\n",
    "    weights_record = []\n",
    "    for i in range(num_portfolios):\n",
    "        weights = np.random.random(len(mean_returns))\n",
    "        weights /= np.sum(weights)\n",
    "        weights_record.append(weights)\n",
    "        portfolio_return = np.sum(mean_returns * weights)\n",
    "        portfolio_std_dev = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
    "        results[0,i] = portfolio_std_dev\n",
    "        results[1,i] = portfolio_return\n",
    "        results[2,i] = (portfolio_return - risk_free_rate) / portfolio_std_dev\n",
    "    return results, weights_record\n",
    "returns = data2.pct_change()\n",
    "mean_returns = returns.mean()\n",
    "cov_matrix = returns.cov()\n",
    "num_portfolios = 25000\n",
    "risk_free_rate = 0.0178\n",
    "\n",
    "def display_simulated_ef_with_random(mean_returns, cov_matrix, num_portfolios, risk_free_rate):\n",
    "    results, weights = random_portfolios(num_portfolios, mean_returns, cov_matrix, risk_free_rate)\n",
    "    max_sharpe_idx = np.argmax(results[2])\n",
    "    sdp, rp = results[0, max_sharpe_idx], results[1, max_sharpe_idx]\n",
    "    max_sharpe_allocation = pd.DataFrame(weights[max_sharpe_idx], index=data2.columns, columns=['allocation'])\n",
    "    max_sharpe_allocation.allocation = [round(i*100, 2) for i in max_sharpe_allocation.allocation]\n",
    "    max_sharpe_allocation = max_sharpe_allocation.T\n",
    "    \n",
    "    min_vol_idx = np.argmin(results[0])\n",
    "    sdp_min, rp_min = results[0, min_vol_idx], results[1, min_vol_idx]\n",
    "    min_vol_allocation = pd.DataFrame(weights[min_vol_idx], index=data2.columns, columns=['allocation'])\n",
    "    min_vol_allocation.allocation = [round(i*100, 2) for i in min_vol_allocation.allocation]\n",
    "    min_vol_allocation = min_vol_allocation.T\n",
    "    \n",
    "    print(\"-\"*80)\n",
    "    print(\"Maximum Sharpe Ratio Portfolio Allocation\\n\")\n",
    "    print(\"Annualised Return:\", round(rp, 2))\n",
    "    print(\"Annualised Volatility:\", round(sdp, 2))\n",
    "    print(\"\\n\")\n",
    "    print(max_sharpe_allocation)\n",
    "    print(\"-\"*80)\n",
    "    print(\"Minimum Volatility Portfolio Allocation\\n\")\n",
    "    print(\"Annualised Return:\", round(rp_min, 2))\n",
    "    print(\"Annualised Volatility:\", round(sdp_min, 2))\n",
    "    print(\"\\n\")\n",
    "    print(min_vol_allocation)\n",
    "# display_simulated_ef_with_random(mean_returns, cov_matrix, num_portfolios, risk_free_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S2a1EzsfpsTk"
   },
   "outputs": [],
   "source": [
    "output=pd.DataFrame(display_simulated_ef_with_random(mean_returns, cov_matrix, num_portfolios,risk_free_rate))\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_xJzJPCDpsR5"
   },
   "outputs": [],
   "source": [
    "def neg_sharpe_ratio(weights, mean_returns, cov_matrix, risk_free_rate):\n",
    "    p_var, p_ret = portfolio_annualised_performance(weights, mean_returns, cov_matrix)\n",
    "    return -(p_ret - risk_free_rate) / p_var\n",
    "\n",
    "def max_sharpe_ratio(mean_returns, cov_matrix, risk_free_rate):\n",
    "    num_assets = len(mean_returns)\n",
    "    args = (mean_returns, cov_matrix, risk_free_rate)\n",
    "    constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})\n",
    "    bound = (0.0,1.0)\n",
    "    bounds = tuple(bound for asset in range(num_assets))\n",
    "    result = sco.minimize(neg_sharpe_ratio, num_assets*[1./num_assets,], args=args,\n",
    "                        method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sPLNrjYdpsP9"
   },
   "outputs": [],
   "source": [
    "def portfolio_volatility(weights, mean_returns, cov_matrix):\n",
    "    return portfolio_annualised_performance(weights, mean_returns, cov_matrix)[0]\n",
    "\n",
    "def min_variance(mean_returns, cov_matrix):\n",
    "    num_assets = len(mean_returns)\n",
    "    args = (mean_returns, cov_matrix)\n",
    "    constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})\n",
    "    bound = (0.0,1.0)\n",
    "    bounds = tuple(bound for asset in range(num_assets))\n",
    "\n",
    "    result = sco.minimize(portfolio_volatility, num_assets*[1./num_assets,], args=args,\n",
    "                        method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def efficient_return(mean_returns, cov_matrix, target):\n",
    "    num_assets = len(mean_returns)\n",
    "    args = (mean_returns, cov_matrix)\n",
    "\n",
    "    def portfolio_return(weights):\n",
    "        return portfolio_annualised_performance(weights, mean_returns, cov_matrix)[1]\n",
    "\n",
    "    constraints = ({'type': 'eq', 'fun': lambda x: portfolio_return(x) - target},\n",
    "                   {'type': 'eq', 'fun': lambda x: np.sum(x) - 1})\n",
    "    bounds = tuple((0,1) for asset in range(num_assets))\n",
    "    result = sco.minimize(portfolio_volatility, num_assets*[1./num_assets,], args=args, method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "    return result\n",
    "\n",
    "\n",
    "def efficient_frontier(mean_returns, cov_matrix, returns_range):\n",
    "    efficients = []\n",
    "    for ret in returns_range:\n",
    "        efficients.append(efficient_return(mean_returns, cov_matrix, ret))\n",
    "    return efficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_calculated_ef_with_random(mean_returns, cov_matrix,num_portfolios, risk_free_rate):\n",
    "    results, _ = random_portfolios(num_portfolios,mean_returns,cov_matrix, risk_free_rate)\n",
    "    \n",
    "    max_sharpe = max_sharpe_ratio(mean_returns, cov_matrix, risk_free_rate)\n",
    "    sdp, rp = portfolio_annualised_performance(max_sharpe['x'], mean_returns, cov_matrix)\n",
    "    max_sharpe_allocation = pd.DataFrame(max_sharpe.x,index=table.columns,columns=['allocation'])\n",
    "    max_sharpe_allocation.allocation = [round(i*100,2)for i in max_sharpe_allocation.allocation]\n",
    "    max_sharpe_allocation = max_sharpe_allocation.T\n",
    "    max_sharpe_allocation\n",
    "\n",
    "    min_vol = min_variance(mean_returns, cov_matrix)\n",
    "    sdp_min, rp_min = portfolio_annualised_performance(min_vol['x'], mean_returns, cov_matrix)\n",
    "    min_vol_allocation = pd.DataFrame(min_vol.x,index=table.columns,columns=['allocation'])\n",
    "    min_vol_allocation.allocation = [round(i*100,2)for i in min_vol_allocation.allocation]\n",
    "    min_vol_allocation = min_vol_allocation.T\n",
    "    \n",
    "    print (\"-\"*80)\n",
    "    print (\"Maximum Sharpe Ratio Portfolio Allocation\\n\")\n",
    "    print (\"Annualised Return:\", round(rp,2))\n",
    "    print (\"Annualised Volatility:\", round(sdp,2))\n",
    "    print (\"\\n\")\n",
    "    print (max_sharpe_allocation)\n",
    "    print (\"-\"*80)\n",
    "    print (\"Minimum Volatility Portfolio Allocation\\n\")\n",
    "    print (\"Annualised Return:\", round(rp_min,2))\n",
    "    print (\"Annualised Volatility:\", round(sdp_min,2))\n",
    "    print (\"\\n\")\n",
    "    print (min_vol_allocation)\n",
    "    \n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.scatter(results[0,:],results[1,:],c=results[2,:],cmap='YlGnBu', marker='o', s=10, alpha=0.3)\n",
    "    plt.colorbar()\n",
    "    plt.scatter(sdp,rp,marker='*',color='r',s=500, label='Maximum Sharpe ratio')\n",
    "    plt.scatter(sdp_min,rp_min,marker='*',color='g',s=500, label='Minimum volatility')\n",
    "\n",
    "    target = np.linspace(rp_min, 0.32, 50)\n",
    "    efficient_portfolios = efficient_frontier(mean_returns, cov_matrix, target)\n",
    "    plt.plot([p['fun'] for p in efficient_portfolios], target, linestyle='-.', color='black', label='efficient frontier')\n",
    "    plt.title('Calculated Portfolio Optimization based on Efficient Frontier')\n",
    "    plt.xlabel('annualised volatility')\n",
    "    plt.ylabel('annualised returns')\n",
    "    plt.legend(labelspacing=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_calculated_ef_with_random(mean_returns, cov_matrix, num_portfolios, risk_free_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Define your utility functions here\n",
    "table=data2\n",
    "def neg_sharpe_ratio(weights, mean_returns, cov_matrix, risk_free_rate):\n",
    "    p_var, p_ret = portfolio_annualised_performance(weights, mean_returns, cov_matrix)\n",
    "    return -(p_ret - risk_free_rate) / p_var\n",
    "\n",
    "def max_sharpe_ratio(mean_returns, cov_matrix, risk_free_rate):\n",
    "    num_assets = len(mean_returns)\n",
    "    args = (mean_returns, cov_matrix, risk_free_rate)\n",
    "    constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})\n",
    "    bound = (0.0,1.0)\n",
    "    bounds = tuple(bound for asset in range(num_assets))\n",
    "    result = minimize(neg_sharpe_ratio, num_assets*[1./num_assets,], args=args,\n",
    "                        method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "    return result\n",
    "\n",
    "def portfolio_annualised_performance(weights, mean_returns, cov_matrix):\n",
    "    returns = np.sum(mean_returns*weights ) *252\n",
    "    std = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights))) * np.sqrt(252)\n",
    "    return std, returns\n",
    "\n",
    "def portfolio_volatility(weights, mean_returns, cov_matrix):\n",
    "    return portfolio_annualised_performance(weights, mean_returns, cov_matrix)[0]\n",
    "\n",
    "def min_variance(mean_returns, cov_matrix):\n",
    "    num_assets = len(mean_returns)\n",
    "    args = (mean_returns, cov_matrix)\n",
    "    constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})\n",
    "    bound = (0.0,1.0)\n",
    "    bounds = tuple(bound for asset in range(num_assets))\n",
    "\n",
    "    result = minimize(portfolio_volatility, num_assets*[1./num_assets,], args=args,\n",
    "                        method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "\n",
    "    return result\n",
    "\n",
    "def efficient_return(mean_returns, cov_matrix, target):\n",
    "    num_assets = len(mean_returns)\n",
    "    args = (mean_returns, cov_matrix)\n",
    "\n",
    "    def portfolio_return(weights):\n",
    "        return portfolio_annualised_performance(weights, mean_returns, cov_matrix)[1]\n",
    "\n",
    "    constraints = ({'type': 'eq', 'fun': lambda x: portfolio_return(x) - target},\n",
    "                   {'type': 'eq', 'fun': lambda x: np.sum(x) - 1})\n",
    "    bounds = tuple((0,1) for asset in range(num_assets))\n",
    "    result = minimize(portfolio_volatility, num_assets*[1./num_assets,], args=args, method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "    return result\n",
    "\n",
    "def efficient_frontier(mean_returns, cov_matrix, returns_range):\n",
    "    efficients = []\n",
    "    for ret in returns_range:\n",
    "        efficients.append(efficient_return(mean_returns, cov_matrix, ret))\n",
    "    return efficients\n",
    "\n",
    "def display_calculated_ef_with_random(mean_returns, cov_matrix,num_portfolios, risk_free_rate):\n",
    "    results, _ = random_portfolios(num_portfolios,mean_returns,cov_matrix, risk_free_rate)\n",
    "    \n",
    "    max_sharpe = max_sharpe_ratio(mean_returns, cov_matrix, risk_free_rate)\n",
    "    sdp, rp = portfolio_annualised_performance(max_sharpe['x'], mean_returns, cov_matrix)\n",
    "    max_sharpe_allocation = pd.DataFrame(max_sharpe.x,index=table.columns,columns=['allocation'])\n",
    "    max_sharpe_allocation.allocation = [round(i*100,2)for i in max_sharpe_allocation.allocation]\n",
    "    max_sharpe_allocation = max_sharpe_allocation.T\n",
    "    max_sharpe_allocation\n",
    "\n",
    "    min_vol = min_variance(mean_returns, cov_matrix)\n",
    "    sdp_min, rp_min = portfolio_annualised_performance(min_vol['x'], mean_returns, cov_matrix)\n",
    "    min_vol_allocation = pd.DataFrame(min_vol.x,index=table.columns,columns=['allocation'])\n",
    "    min_vol_allocation.allocation = [round(i*100,2)for i in min_vol_allocation.allocation]\n",
    "    min_vol_allocation = min_vol_allocation.T\n",
    "    \n",
    "    print (\"-\"*80)\n",
    "    print (\"Maximum Sharpe Ratio Portfolio Allocation\\n\")\n",
    "    print (\"Annualised Return:\", round(rp,2))\n",
    "    print (\"Annualised Volatility:\", round(sdp,2))\n",
    "    print (\"\\n\")\n",
    "    print (max_sharpe_allocation)\n",
    "    print (\"-\"*80)\n",
    "    print (\"Minimum Volatility Portfolio Allocation\\n\")\n",
    "    print (\"Annualised Return:\", round(rp_min,2))\n",
    "    print (\"Annualised Volatility:\", round(sdp_min,2))\n",
    "    print (\"\\n\")\n",
    "    print (min_vol_allocation)\n",
    "    \n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.scatter(results[0,:],results[1,:],c=results[2,:],cmap='YlGnBu', marker='o', s=10, alpha=0.3)\n",
    "    plt.colorbar()\n",
    "    plt.scatter(sdp,rp,marker='*',color='r',s=500, label='Maximum Sharpe ratio')\n",
    "    plt.scatter(sdp_min,rp_min,marker='*',color='g',s=500, label='Minimum volatility')\n",
    "\n",
    "    target = np.linspace(rp_min, 0.32, 50)\n",
    "    efficient_portfolios = efficient_frontier(mean_returns, cov_matrix, target)\n",
    "    plt.plot([p['fun'] for p in efficient_portfolios], target, linestyle='-.', color='black', label='efficient frontier')\n",
    "    plt.title('Calculated Portfolio Optimization based on Efficient Frontier')\n",
    "    plt.xlabel('annualised volatility')\n",
    "    plt.ylabel('annualised returns')\n",
    "    plt.legend(labelspacing=0.8)\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# display_calculated_ef_with_random(mean_returns, cov_matrix, num_portfolios, risk_free_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_calculated_ef_with_random(mean_returns, cov_matrix, num_portfolios, risk_free_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_aWMFjFC2qii",
    "outputId": "4d8c8a58-c410-467b-864d-95473c4c6f9c"
   },
   "outputs": [],
   "source": [
    "'''import pandas as pd\n",
    "\n",
    "# Assuming your data is stored in a DataFrame named 'df1' with a column 'Sector' indicating the sector of each stock\n",
    "\n",
    "# Extract unique sectors from your data\n",
    "unique_sectors = df1['Sector'].unique()\n",
    "\n",
    "# Define empty dictionaries to store sector mappings and constraints\n",
    "sector_mapper = {}\n",
    "sector_lower = {}\n",
    "sector_upper = {}\n",
    "\n",
    "# Assign sectors to sector_mapper and set initial constraints\n",
    "for sector in unique_sectors:\n",
    "    sector_mapper.update({stock: sector for stock in df1[df1['Sector'] == sector].index})\n",
    "    sector_lower[sector] = 0  # at least 0% allocation to the sector initially\n",
    "    sector_upper[sector] = 1  # at most 100% allocation to the sector initially\n",
    "\n",
    "# Update constraints if needed (e.g., you want to set specific lower and upper bounds for each sector)\n",
    "\n",
    "# Print the sector mappings and constraints\n",
    "print(\"Sector Mapper:\")\n",
    "print(sector_mapper)\n",
    "print(\"\\nSector Lower Bounds:\")\n",
    "print(sector_lower)\n",
    "print(\"\\nSector Upper Bounds:\")\n",
    "print(sector_upper)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-dXkSmj0hIMx"
   },
   "outputs": [],
   "source": [
    "# # DISCRETE ALLOCATION OF EFFICIENT FRONTIER\n",
    "# from pypfopt.discrete_allocation import DiscreteAllocation, get_latest_prices\n",
    "# portfolio_amount = float(input(\"Enter the amount you want to invest: \"))\n",
    "# if portfolio_amount != '' :\n",
    "#     # Get discrete allocation of each share per stock\n",
    "\n",
    "#     latest_prices = get_latest_prices(df)\n",
    "#     weights = cleaned_weights\n",
    "#     discrete_allocation = DiscreteAllocation(weights, latest_prices , total_portfolio_value = int(portfolio_amount))\n",
    "#     allocation , leftover = discrete_allocation.lp_portfolio()\n",
    "\n",
    "#     discrete_allocation_list = []\n",
    "\n",
    "\n",
    "#     for symbol in allocation:\n",
    "#         discrete_allocation_list.append(allocation.get(symbol))\n",
    "\n",
    "\n",
    "#     portfolio_df = pd.DataFrame(columns =['Ticker' , 'Number of stocks to buy'])\n",
    "\n",
    "#     portfolio_df['Ticker'] = allocation\n",
    "#     portfolio_df['Number of stocks to buy'] = discrete_allocation_list\n",
    "#     print('Number of stocks to buy with the amount of ₨ ' + str(portfolio_amount))\n",
    "#     print(portfolio_df)\n",
    "#     print('Funds remaining with you will be: ₨' , int(leftover))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mwPFDntahPD7"
   },
   "outputs": [],
   "source": [
    "# SHARPE RATIO FOR EFFICIENT CVAR\n",
    "from pypfopt import expected_returns, risk_models\n",
    "from pypfopt import EfficientCVaR\n",
    "import pandas as pd\n",
    "\n",
    "# Assume you have already defined mu, S, and ef as per your code snippet\n",
    "\n",
    "# Calculate the expected returns and the covariance matrix of the portfolio\n",
    "mu = expected_returns.mean_historical_return(data2)\n",
    "S = risk_models.sample_cov(data2)\n",
    "\n",
    "# Create the Efficient Frontier Object with CVaR\n",
    "ef = EfficientCVaR(mu, S)\n",
    "\n",
    "# Add sector constraints to the Efficient Frontier\n",
    "ef.add_sector_constraints(sector_mapper, sector_lower, sector_upper)\n",
    "\n",
    "# Optimize for the minimum CVaR\n",
    "weights = ef.min_cvar()\n",
    "\n",
    "# Clean the raw weights and print them\n",
    "cleaned_weights = ef.clean_weights()\n",
    "print(cleaned_weights)\n",
    "\n",
    "# Calculate the portfolio performance\n",
    "# Assuming you have risk-free rate and daily returns of the portfolio available\n",
    "# Replace rf_rate with the actual risk-free rate\n",
    "rf_rate = 0.02 / 252  # Assuming an annual risk-free rate of 2%, converted to daily rate\n",
    "portfolio_returns = ef.portfolio_performance()[0]  # Portfolio returns\n",
    "portfolio_volatility = ef.portfolio_performance()[1]  # Portfolio volatility (standard deviation)\n",
    "\n",
    "# Calculate Sharpe Ratio\n",
    "sharpe_ratio = (portfolio_returns - rf_rate) / portfolio_volatility\n",
    "\n",
    "# Print the Sharpe Ratio\n",
    "print(\"Sharpe Ratio:\", sharpe_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cUbeqmw6hRtK"
   },
   "outputs": [],
   "source": [
    "# # DISCRETE ALLOCATION OF EFFICIENT CVAR\n",
    "# from pypfopt.discrete_allocation import DiscreteAllocation, get_latest_prices\n",
    "# portfolio_amount = float(input(\"Enter the amount you want to invest: \"))\n",
    "# if portfolio_amount != '' :\n",
    "#     # Get discrete allocation of each share per stock\n",
    "\n",
    "#     latest_prices = get_latest_prices(df)\n",
    "#     weights = cleaned_weights\n",
    "#     discrete_allocation = DiscreteAllocation(weights, latest_prices,total_portfolio_value = int(portfolio_amount))\n",
    "#     allocation , leftover = discrete_allocation.lp_portfolio()\n",
    "\n",
    "#     discrete_allocation_list = []\n",
    "\n",
    "\n",
    "#     for symbol in allocation:\n",
    "#         discrete_allocation_list.append(allocation.get(symbol))\n",
    "\n",
    "\n",
    "#     portfolio_df = pd.DataFrame(columns =['Ticker' , 'Number of stocks to buy'])\n",
    "\n",
    "#     portfolio_df['Ticker'] = allocation\n",
    "#     portfolio_df['Number of stocks to buy'] = discrete_allocation_list\n",
    "#     print('Number of stocks to buy with the amount of ₨ ' + str(portfolio_amount))\n",
    "#     print(portfolio_df)\n",
    "#     print('Funds remaining with you will be: ₨' , int(leftover))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T6X-zPkwhXOI"
   },
   "outputs": [],
   "source": [
    "'''import matplotlib.pyplot as plt\n",
    "\n",
    "#Your portfolio weights\n",
    "weights = {\n",
    "   'Reliance': 0.11172,\n",
    "   'ONGC': 0.03206,\n",
    "   'Adani': 0.16544,\n",
    "    'Asian Paints': 0.21898,\n",
    "    'UltraTech': 0.08102,\n",
    "    'Maruti Suzuki': 0.1,\n",
    "    'Tata Motors': 0.0,\n",
    "    'HCL': 0.21405,\n",
    "    'TCS': 0.08595,\n",
    "    'Infosys': 0.0\n",
    "}\n",
    "\n",
    "#The values are your portfolio weights\n",
    "values = list(weights.values())\n",
    "\n",
    "#The labels are the stock names\n",
    "labels = list(weights.keys())\n",
    "\n",
    "#Create the pie chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.pie(values, labels=labels, autopct='%1.1f%%')\n",
    "\n",
    "#Display the plot\n",
    "plt.show()'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REBALANCING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "non_zero_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of companies\n",
    "companies = [\n",
    "    'APAR Industries Limited',\n",
    "    'APL Apollo Tubes Limited',\n",
    "    'Abbott India Limited',\n",
    "    'Adani Enterprises Limited',\n",
    "    'Bajaj Finance Limited',\n",
    "    'Bajaj Holdings & Investment Limited',\n",
    "    'Bharti Airtel Limited',\n",
    "    'Britannia Industries Limited',\n",
    "    'Cantabil Retail India Limited',\n",
    "    'Grindwell Norton Limited',\n",
    "    'Hindustan Petroleum Corporation Limited',\n",
    "    'Info Edge (India) Limited',\n",
    "    'JBM Auto Limited',\n",
    "    'KNR Constructions Limited',\n",
    "    'Kingfa Science & Technology (India) Limited',\n",
    "    'MPS Limited',\n",
    "    'Muthoot Finance Limited',\n",
    "    'Olectra Greentech Limited',\n",
    "    'Persistent Systems Limited',\n",
    "    'Petronet LNG Limited',\n",
    "    'Power Grid Corporation of India Limited',\n",
    "    'Procter & Gamble Hygiene and Health Care Limited',\n",
    "    'Ratnamani Metals & Tubes Limited',\n",
    "    'Reliance Industries Limited',\n",
    "    'SJVN Limited',\n",
    "    'Solar Industries India Limited',\n",
    "    'Tanla Platforms Limited',\n",
    "    'Tata Communications Limited',\n",
    "    'The Phoenix Mills Limited',\n",
    "    'Torrent Pharmaceuticals Limited',\n",
    "    'Uno Minda Limited'\n",
    "]\n",
    "\n",
    "# List of weights\n",
    "weights = [\n",
    "    0.01873,\n",
    "    0.04668,\n",
    "    0.09293,\n",
    "    0.02688,\n",
    "    0.07044,\n",
    "    0.02727,\n",
    "    0.00171,\n",
    "    0.04585,\n",
    "    0.02809,\n",
    "    0.03389,\n",
    "    0.00433,\n",
    "    0.04472,\n",
    "    0.03117,\n",
    "    0.00807,\n",
    "    0.0122,\n",
    "    0.02347,\n",
    "    0.00229,\n",
    "    0.03932,\n",
    "    0.04366,\n",
    "    0.01083,\n",
    "    0.06563,\n",
    "    0.05415,\n",
    "    0.02094,\n",
    "    0.0169,\n",
    "    0.03437,\n",
    "    0.02018,\n",
    "    0.05634,\n",
    "    0.02551,\n",
    "    0.04566,\n",
    "    0.00707,\n",
    "    0.04074\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = '^BSESN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter df1 based on the list of companies\n",
    "filtered_df = df1[df1['company'].isin(companies)]\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new1=filtered_df.pivot_table(index='Date',columns= 'company', values='Adj Close')\n",
    "new1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shares_df = pd.DataFrame(index=[new1.index[0]])\n",
    "portfolio_value = 10**7\n",
    "for s,w in zip(companies, weights):\n",
    "    shares_df[s + '_shares'] = np.floor((portfolio_value * np.array(w)) / new1[s][0])\n",
    "\n",
    "shares_df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REBALANCING ENGINE (change between .year, .month, .day to execute the rebalancing)\n",
    "\n",
    "# set initial shares on the first day\n",
    "shares_df.loc[new1.index[0], :] = [np.floor((portfolio_value * w) / new1[s][0]) for s,w in zip(companies, weights)]\n",
    "\n",
    "# initialize variables\n",
    "balance_year = new1.index[0].year\n",
    "signal = False\n",
    "count = 0    # for loop count purpose\n",
    "\n",
    "# Store previous values in a dictionary\n",
    "prev_values = {}\n",
    "\n",
    "# Calculate portfolio value for the first day\n",
    "portfolio_value = sum([shares_df.loc[new1.index[0], s + '_shares'] * new1.loc[new1.index[0], s] for s in companies])\n",
    "\n",
    "for day in new1.index:\n",
    "    count += 1\n",
    "    if day == new1.index[0]:\n",
    "        shares_df.loc[day] = shares_df.loc[day] # First day\n",
    "\n",
    "        # Store initial values as previous values\n",
    "        for col in shares_df.columns:\n",
    "            prev_values[col] = shares_df.loc[day, col]\n",
    "\n",
    "\n",
    "    elif day.year != balance_year:\n",
    "        signal = True\n",
    "        # calculate new shares based on the new portfolio value and weights\n",
    "        new_shares = [np.floor((portfolio_value * w) / new1[s][day]) for s,w in zip(companies, weights)]\n",
    "        shares_df.loc[day, :] = new_shares\n",
    "        balance_year = day.year\n",
    "        count += 1\n",
    "        # print(f'Rebalance: {day.date()}, count: {count}') # uncomment to debug days ;)\n",
    "        # Store new values as previous values\n",
    "        for col in shares_df.columns:\n",
    "            prev_values[col] = shares_df.loc[day, col]\n",
    "\n",
    "    else:\n",
    "\n",
    "        signal = False\n",
    "\n",
    "        # Use previous values if it is not a rebalancing date\n",
    "        shares_df.loc[day, :] = [prev_values[col] for col in shares_df.columns]\n",
    "        \n",
    "        # print(f'Not rebalance, regular day: {day.date()}') # uncomment to debug days ;)\n",
    "\n",
    "\n",
    "\n",
    "    # Calculate asset values and portfolio value for the current day\n",
    "    asset_values = [shares_df.loc[day, s + '_shares'] * new1.loc[day, s] for s in companies]\n",
    "    portfolio_value = sum(asset_values)\n",
    "    \n",
    "    new1.loc[day, 'Signal'] = signal\n",
    "    new1.loc[day, 'Portfolio_Value'] = portfolio_value\n",
    "    \n",
    "    # Add shares to stock data frame\n",
    "    for s in companies:\n",
    "        new1.loc[day, s + '_shares'] = shares_df.loc[day, s + '_shares']\n",
    "        new1.loc[day, s + '_value'] = shares_df.loc[day, s + '_shares'] * new1.loc[day, s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate log returns for portfolio\n",
    "new1['Portfolio_Value_rets'] = np.log(new1['Portfolio_Value'] / new1['Portfolio_Value'].shift(1))\n",
    "\n",
    "# Calculate log returns for each stock\n",
    "for stock in companies:\n",
    "    new1[f'{stock}_rets'] = np.log(new1[stock] / new1[stock].shift(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date_benchmark = new1.index[0]\n",
    "new1 = new1.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate daily weight per asset\n",
    "for s in companies:\n",
    "    new1[s + '_weight'] = new1[s + '_value'] / new1['Portfolio_Value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new1.filter(regex='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "fig = go.Figure()\n",
    "\n",
    "# Loop through each stock and add a trace for its shares\n",
    "for stock in companies:\n",
    "    fig.add_trace(go.Scatter(x=new1.index, y=shares_df[stock+'_shares'], mode='lines', name=stock+'_shares'))\n",
    "\n",
    "fig.update_layout(title='Shares per day',\n",
    "                  xaxis_title='Date',\n",
    "                  yaxis_title='Shares',\n",
    "                  width=800,\n",
    "                  height=400)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "# Loop through each stock and add a trace for its shares\n",
    "for stock in companies:\n",
    "    fig.add_trace(go.Scatter(x=new1.index, y=new1[stock + '_weight'], mode='lines', name=stock + '_weight'))\n",
    "\n",
    "fig.update_layout(title='Weights per day',\n",
    "                  xaxis_title='Date',\n",
    "                  yaxis_title='Weights',\n",
    "                  width=1000,\n",
    "                  height=600)\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Create subplot layout\n",
    "fig = make_subplots(rows=2, cols=2, subplot_titles=('Portfolio Returns', 'Asset Returns', 'Shares Holding per Asset', 'Weights per Asset'))\n",
    "\n",
    "# Add traces to the subplots\n",
    "fig.add_trace(go.Scatter(x=new1.index, y=new1['Portfolio_Value_rets'].cumsum(), name='Portfolio'), row=1, col=1)\n",
    "\n",
    "for s in companies:\n",
    "    fig.add_trace(go.Scatter(x=new1.index, y=new1[f'{s}_rets'].cumsum(), name=f'{s}'), row=1, col=2)\n",
    "    fig.add_trace(go.Scatter(x=shares_df.index, y=shares_df[f'{s}_shares'], name=f'{s}'), row=2, col=1)\n",
    "    fig.add_trace(go.Scatter(x=new1.index, y=new1[f'{s}_weight'], name=f'{s}'), row=2, col=2)\n",
    "\n",
    "# Update subplot layout\n",
    "fig.update_layout(height=800, width=1200, title='Strategy Overview', showlegend=False)\n",
    "\n",
    "# Display the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISCRETE ALLOCATION OF EFFICIENT FRONTIER\n",
    "from pypfopt.discrete_allocation import DiscreteAllocation, get_latest_prices\n",
    "import pandas as pd\n",
    "\n",
    "# Function to convert INR to USD\n",
    "def inr_to_usd(amount_inr):\n",
    "    # Assuming 1 USD = 75 INR\n",
    "    return amount_inr / 75.0\n",
    "\n",
    "portfolio_amount_inr = float(input(\"Enter the amount you want to invest (INR): \"))\n",
    "\n",
    "# Convert INR to USD\n",
    "portfolio_amount_usd = inr_to_usd(portfolio_amount_inr)\n",
    "\n",
    "if portfolio_amount_inr != '':\n",
    "    # Get discrete allocation of each share per stock\n",
    "    latest_prices = get_latest_prices(data2)\n",
    "    weights = cleaned_weights\n",
    "    discrete_allocation = DiscreteAllocation(weights, latest_prices, total_portfolio_value=int(portfolio_amount_usd))\n",
    "    allocation, leftover = discrete_allocation.lp_portfolio()\n",
    "\n",
    "    discrete_allocation_list = []\n",
    "\n",
    "    for symbol in allocation:\n",
    "        discrete_allocation_list.append(allocation.get(symbol))\n",
    "\n",
    "    portfolio_df = pd.DataFrame(columns=['Ticker', 'Number of stocks to buy'])\n",
    "    portfolio_df['Ticker'] = allocation\n",
    "    portfolio_df['Number of stocks to buy'] = discrete_allocation_list\n",
    "\n",
    "    # Convert leftover USD to INR\n",
    "    leftover_inr = leftover * 75\n",
    "\n",
    "    print('Number of stocks to buy with the amount of ₨', portfolio_amount_inr)\n",
    "    print(portfolio_df)\n",
    "    print('Funds remaining with you will be: ₨', int(leftover_inr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_prices.loc['Reliance Communications Limited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "500-(2.0999999046325684*75*1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
